%& --translate-file=cp1250pl
\documentclass[11pt,a4paper]{article}
\usepackage[left=3.5cm, right=4cm, bottom=6.65cm, top=5cm]{geometry}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage{setspace}
\usepackage{array}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{multicol}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{times}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{multirow}
\include{pbwlib}

%=========================================================================%
%========================== Author(s) & Title ============================%
%=========================================================================%

\begin{document}
%
\Booktitle{Computer Systems Engineering 2007 (co tu wpisac?)}
%
\Keywords{american sign language, images recognition, machine learning}
%

\noindent Mi\l osz BIA\L CZAK\footnote{\noindent Wroc\l aw University of Science and Technology, Poland\label{pwr1}} \\
%
\noindent Martyna \L AGO\.ZNA\textsuperscript{\ref{pwr1}} \\[7pt]
%
\Title{AMERICAN SIGN LANGUAGE RECOGNITION}


%=========================================================================%
%============================== Abstract =================================%
%=========================================================================%

\Abstract{
	What if the fast development of computer science, especially machine learning could help disabled people? In fact, it can and this is the topic to which the research described in this paper has been devoted. Deaf-mute people are the part of our society and it would be a great convenience both for them and speaking people which would allow for a better communication using technology. In this paper, the results of research concerning recognition of sign language has been shared. The research includes experimenting with the images transformations and usage of different learning and features detecting algorithms to obtain the best quality of signs recognition. In addition the part of this work has been also the impact of background and different hands rotation.
}


%=========================================================================%
%=========================== INTRODUCTION ================================%
%=========================================================================%

\section{INTRODUCTION}

	Nowadays, using technology to solve medical issues is becoming a common practice[]. Constant and fast development of science and growing popularity of machine learning allow for creating technologically advanced appliances and complex algorithms which are aimed at helping people. Sign language recognition is an interesting and significant issue strictly connected with both machine learning and medical technology. Deaf-mute people pose X\% of the whole society[]. In the past there were no technical possibilities to facilitate their lives and communication ways. Now it is still challenging but possible so we attempted to solve this issue. 

	In this work we decided to experiment with different features extraction and learning algorithms and pay particular attention on image processing. Moreover the scope of this work includes also checking the impact of background and hands rotations on received accuracy based on usage 2 completely different data sets.
	
	Our approach to this problem at the current stage is based on recognition of single letters from American sign language alphabet. One of the crucial assumptions of this work is recognition of images taken with average-quality camera because the algorithm which has been implemented should be available for everyone for example by a build-in camera in mobile phone or computer.
	
	
	
	
	

	
%=========================================================================%
%========================= PROBLEM FORMULATION ===========================%
%=========================================================================%

\section{PROBLEM FORMULATION}

	The objective of this work is to create an algorithm which recognizes static gestures of single letters from American sign language alphabet with the highest possible accuracy. The algorithm should be given an image in .jpg format on input and the result should be returned as recognized letter on string type. To implement the algorithm, it is necessary to consider the problems as follows:
	
* finding crucial features and point on the picture

* emphasizing of hand features
	
* finding satisfying way of learning the algorithm.








%=========================================================================%
%============================= ALGORITHMS ================================%
%=========================================================================%

\section{ALGORITHMS}

	In this section, the algorithms used in this work are being described.

\subsection{Preprocessing}
	
	To prepare the set of images and improve received results Gaussian blur and anisotropic filtering has been used. Gaussian blur is a method of modification the image with Gaussian function. It is commonly used to reduce image noise and reduce details. Anisotropic filtering is a technique of enhancing the image quality... nie wiem co tu napsiac o tym, trzeba poczukac odwolania do czegos madrego o tym. In our work we used Gaussian blur to avoid recognition of unimportant and excess points which potentially could be found by the algorithm. At the same time, to sharpen the shape of hand and to not lose the main shape of the gesture anisotropic filtering has been applied.

\subsection{Features extraction}

- CENSURE - new we give o shot

- BRIEF - old without of rotation features

- ORB - boosted BRIEF good working with rotations

\subsection{Postprocessing}

- Standard Scaler - other kind of normalization with point of mass

- Normalize - one kind of normalization

\subsection{Learning}

Support Vector Machines (SVMs) are a set of related methods for supervised learning, applicable to both classification and regression problems. A SVM classifiers creates a maximum-margin hyperplane that lies in a transformed input space and splits the example classes, while maximizing the distance to the nearest cleanly split examples. The parameters of the solution hyperplane are derived from a quadratic programming optimization problem\cite{SVM1}.

- points - algorithm learned point after point from picture, with saying "that point is from that sign".

- vector - algorithm learned by vector of points from picture with information "vector like that is that sign".

- combined - using both points and vector classifiers, and learn from they outputs, with one is correct.  

%=========================================================================%
%================================ EXPERIMENTS ============================%
%=========================================================================%

\section{EXPERIMENT}

\subsection{Data sets}
	In this experiment two different data sets has been used. The first one has been downloaded from the website of Silesian University of Technology[czy tu powinien byc odnosnik do tego zbioru?]. It consists of 899 images of gestures from American aplhabet form A to Y excluding J. Letters 'Z' and 'J' are moving gestures and it is impossible to show them on single picture. This data set contains images with uncontrolled background and lightning conditions, different angle of hand rotations form observer perspective and different resolution. Images are oriented both vertically and horizontally.
	
	The second data set used in the experiment is a self-made set of images which has been created in possibly similar lightning condition. On each image only hands at uniform, plain background has been shown. Each image has exactly the same, high resolution and all of them are oriented horizontally. The set contains images of gestures of all American sign alphabet also with 'J' and 'Z' excluded.


%=========================================================================%
%======================== RESULTS OF EXPERIMENTS =========================%
%=========================================================================%

\section{RESULTS}

Bla... Bla... Bla... Results of research by adding next step to algorithm.

OPTION A 

%Wykresy dla danych z Politechniki Śląskiej i dla naszych.
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|}
	\cline{2-10}
	\multirow{2}{*}{ } & \multicolumn{3}{ |c| }{ORB} & \multicolumn{3}{ |c| }{CENSURE} & \multicolumn{3}{ |c| }{BRIEF} \\
	\cline{2-10}
	& points & combine & vector & points & combine & vector & points & combine & vector \\
	\hline
	\multicolumn{1}{ |c| }{descriptors} & 51.72\% & 13.79\% & 13.79\% & 20.69\% & 13.79\% & 8.61\% & 15.52\% & 15.52\% & 0.00\% \\
	\hline
	\multicolumn{1}{ |c| }{anisotropic filtering} & 60.34\% & 13.79\% & 13.79\% & 22.41\% & 18.97\% & 1.72\% & - & - & - \\
	\hline
	\multicolumn{1}{ |c| }{StandardScaler} & 91.38\% & 12.07\% & 13.79\% & 15.52\% & 15.52\% & 0.00\% & - & - & - \\
	\hline
	\multicolumn{1}{ |c| }{Gaussian blur} & 94.84\% & 13.79\% & 22.41\% & 12.07\% & 5.17\% & 1.72\% & - & - & - \\
	\hline
	\multicolumn{1}{ |c| }{normalization} & 96.55\% & 12.07\% & 25.86\% & - & - & - & - & - & - \\
	\hline
\end{tabular} \\\\

OPTION B 

\begin{tabular}{c|c|c|c|}
	\cline{2-4}
	\multirow{2}{*}{ } & \multicolumn{3}{ |c| }{ORB} \\
	\cline{2-4}
	& points & combine & vector \\
	\hline
	\multicolumn{1}{ |c| }{descriptors} & 51.72\% & 13.79\% & 13.79\% \\
	\hline
	\multicolumn{1}{ |c| }{anisotropic filtering} & 60.34\% & 13.79\% & 13.79\% \\
	\hline
	\multicolumn{1}{ |c| }{StandardScaler} & 91.38\% & 12.07\% & 13.79\% \\
	\hline
	\multicolumn{1}{ |c| }{Gaussian blur} & 94.84\% & 13.79\% & 22.41\% \\
	\hline
	\multicolumn{1}{ |c| }{normalization} & 96.55\% & 12.07\% & 25.86\% \\
	\hline
\end{tabular} \\\\

\begin{tabular}{c|c|c|c|}
\cline{2-4}
\multirow{2}{*}{ } & \multicolumn{3}{ |c| }{CENSURE} \\
\cline{2-4}
& points & combine & vector \\
\hline
\multicolumn{1}{ |c| }{descriptors} & 20.69\% & 13.79\% & 8.61\% \\
\hline
\multicolumn{1}{ |c| }{anisotropic filtering} & 22.41\% & 18.97\% & 1.72\% \\
\hline
\multicolumn{1}{ |c| }{StandardScaler} & 15.52\% & 15.52\% & 0.00\% \\
\hline
\multicolumn{1}{ |c| }{Gaussian blur} & 12.07\% & 5.17\% & 1.72\% \\
\hline
\end{tabular} \\\\

\begin{tabular}{c|c|c|c|}
\cline{2-4}
\multirow{2}{*}{ } & \multicolumn{3}{ |c| }{BRIEF} \\
\cline{2-4}
& points & combine & vector \\
\hline
\multicolumn{1}{ |c| }{descriptors} & 15.52\% & 15.52\% & 0.00\% \\
\hline
\end{tabular} \\\\



Bla... Bla... Bla... Results of research for different datasets by final algorithm.\\


\begin{tabular}{|p{5cm}|c|c|c|}
	%\hline
	\cline{1-4}
	\multirow{2}{*}{ } & \multicolumn{3}{ |c| }{ORB} \\
	\cline{2-4}
	& points & combine & vector\\
	\hline
	Our set of numbers & 96.55\% & 12.07\% & 25.86\% \\
	\hline
	Our set of alphabet & 72.90\% & 3.23\% & 12.26\% \\
	\hline
	Set of Silesian University of Technology alphabet & 27.36\% & 3.48\% & 2.49\% \\
	\hline
\end{tabular} 


%=========================================================================%
%============================== CONCLUSION ===============================%
%=========================================================================%

\section{CONCLUSION AND PERSPECTIVES}


* correct recognition independently of skin color

%=========================================================================%
%============================== BIBLIOGRAPHY ===============================%
%=========================================================================%

\begin{thebibliography}{99}
\refefencesize \setlength\baselineskip{5pt}
%
\bibitem{SVM1} Shmilovici Armin \textit{Support Vector Machines} Data Mining and Knowledge Discovery Handbook pp 231-247.




EXAMPLES:
\bibitem{CR76} CARLSON J.G. and ROWE R.G., \textit{How much does forgetting cost?} Industrial Engineering, vol. 8, 1976 pp. 40--47.
\bibitem{GG40} GRAHAM C.H. and  GAGNE R.M., \textit{The acquisition, extinction, and spontaneous recovery of conditioned operant response}. Journal of Experimental Psychology, vol. 26, 1940, pp. 251--280.
\bibitem{JB99} JABER Y.M. and BONNEY M., \textit{The economic manufacture/order quantity (EMQ/EOQ) and the learning curve: Past, present, and future}. International Journal of Production Economics, vol. 59, 1999, pp. 93--102.


\end{thebibliography}



\end{document}